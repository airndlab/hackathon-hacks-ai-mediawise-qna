name: mwgpu

services:
  vllm:
    image: vllm/vllm-openai:v0.6.3
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    ports:
      - 8000:8000
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    networks:
      - mwgpu-net
    command: --model Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4 --quantization gptq --device cuda

networks:
  mwgpu-net:
