name: mwgpu

services:
  vllm:
    image: vllm/vllm-openai:v0.6.3
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    ports:
      - 8000
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    networks:
      - mwgpu-net
    command: --model Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4 --quantization gptq --device cuda

  rag:
    image: airndlab/mediawise-rag:2024.11.20-18-15
    restart: unless-stopped
    depends_on:
      - vllm
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./config:/config
      - ./dataset:/data/dataset
      - ./index:/data/index
    environment:
      - VLLM_URL=http://vllm:8000/v1
      - CHROMA_HOSTNAME=158.160.68.33
      - CHROMA_PORT=8000
      - YANDEX_API_TOKEN=${YANDEX_API_TOKEN:-noteken}
      - MAIN_DOCS_DIR=/data/dataset
      - DOCUMENT_STORES_DIR=/data/index
      - PROMPTS_CONFIG_PATH=/config/prompts.yaml
      - DICTS_CONFIG_PATH=/config/dicts.yaml
      - RAG_CONFIG_PATH=/config/rag.yaml
      - API_CONFIG_PATH=/config/api.yaml
    ports:
      - 8080
    networks:
      - mwgpu-net

networks:
  mwgpu-net:
